{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for repeatability \n",
    "np.random.seed(1) \n",
    "\n",
    "#models (algorithms)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# result validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#our success metric\n",
    "from sklearn.metrics import accuracy_score  \n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plots inside of notebook\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# Load CSV: type \n",
    "df = pd.read_csv(\"./data/polish_names.csv\")\n",
    "\n",
    "# # Convert to gender (f,m) to numeric values (0,1)\n",
    "df['target'] = df['gender'].map(lambda x: int(x == 'm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_model(X_train, X_test, y_train, y_test, model, success_metric=accuracy_score):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return success_metric(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Features from `1_LogisticRegression_prediction` Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vowels = ['a', 'ą', 'e', 'ę', 'i', 'o', 'u', 'y']\n",
    "\n",
    "def how_many_vowels(name):\n",
    "    return sum( map(lambda x: int(x in vowels), name.lower()) )\n",
    "    \n",
    "def first_is_vowel(name):\n",
    "    return name.lower()[0] in vowels\n",
    "\n",
    "def last_is_vowel(name):\n",
    "    return name.lower()[-1] in vowels\n",
    "\n",
    "def get_all_vowels(name):\n",
    "    all_vowels = [letter for letter in name.lower() if letter in vowels]\n",
    "    \n",
    "    return ''.join(all_vowels)\n",
    "\n",
    "def get_all_consonants(name):\n",
    "    all_consonants = [letter for letter in name.lower() if letter not in vowels]\n",
    "    \n",
    "    return ''.join(all_consonants)\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['len_name'] = df['name'].map(lambda x: len(x))\n",
    "    \n",
    "    df['first_is_vowel'] = df['name'].map(first_is_vowel)\n",
    "    df['last_is_vowel'] = df['name'].map(last_is_vowel)\n",
    "    \n",
    "    df['first_letter'] = df['name'].map(lambda x: x.lower()[0])\n",
    "    df['first_letter_cnt'] = pd.factorize(df['first_letter'])[0]\n",
    "    \n",
    "    df['last_letter'] = df['name'].map(lambda x: x.lower()[-1])\n",
    "    df['last_letter_cnt'] = pd.factorize(df['last_letter'])[0]\n",
    "    \n",
    "    df['all_vowels'] = df['name'].map(get_all_vowels)\n",
    "    df['all_vowels_cnt'] = pd.factorize(df['all_vowels'])[0]\n",
    "\n",
    "    df['all_consonants'] = df['name'].map(get_all_consonants)\n",
    "    df['all_consonants_cnt'] = pd.factorize(df['all_consonants'])[0]\n",
    "    \n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9524926686217009"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fe = feature_engineering(df)\n",
    "\n",
    "features = ['len_name', 'first_is_vowel', 'last_is_vowel', 'first_letter_cnt', 'last_letter_cnt', 'all_vowels_cnt', 'all_consonants_cnt']\n",
    "X = df_fe[ features ]\n",
    "y = df_fe['target']\n",
    "\n",
    "train_and_predict_model(X, X, y, y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split for TRAIN and TEST\n",
    "Train: 70%\n",
    "Test: 30% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X before:  (1705, 7)\n",
      "X Train:  (1193, 7)\n",
      "X Test:  (512, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print( \"X before: \", X.shape )\n",
    "print ( \"X Train: \", X_train.shape )\n",
    "print ( \"X Test: \", X_test.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
